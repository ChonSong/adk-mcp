The Agent Development Kit (ADK) is an open-source, **code-first Python toolkit** designed for building, evaluating, and deploying sophisticated AI agents with enhanced flexibility and control. It is built on the philosophy of making agent development feel more like traditional software development, providing modularity and scalability for architectures ranging from simple tasks to complex workflows.

ADK offers a modular and flexible framework that is **model-agnostic** and **deployment-agnostic**, although it is highly optimised for integration with the Google ecosystem and Gemini models.

Here is a very detailed elaboration on the structure, features, capabilities, and lifecycle of ADK, drawing comprehensively from the provided documentation:

---

## I. Agent Architecture and Core Categories

The foundation for all components within ADK is the concept of the **Agent**, defined as a self-contained execution unit derived from the `BaseAgent` class, designed to act autonomously to achieve specific goals. ADK categorizes agents into three primary types, which can be composed into powerful Multi-Agent Systems (MAS):

### 1. LLM Agents (`LlmAgent` or `Agent`)
These agents rely on **Large Language Models (LLMs)** as their core engine for reasoning, planning, generation, and dynamically deciding which tools to use. They are ideal for flexible, language-centric tasks and can be configured with detailed instructions, tools, and constraints.

Key configuration parameters for an `LlmAgent` include:
*   **`model`**: Specifies the underlying LLM (e.g., `"gemini-2.5-flash"`). ADK supports using different models by passing the model name string or by wrapping models from external providers (like GPT or Claude) using the **`LiteLlm`** object, enabling multi-LLM flexibility.
*   **`instruction`**: Provides guidance on the agent's core task, persona, constraints, and how and when to use its `tools`. Effective instructions should be clear, specific, and guide tool usage precisely.
*   **`tools`**: A list of capabilities the agent can invoke, ranging from pre-built functions to custom APIs.
*   **`output_key`**: A powerful feature that automatically saves the agent's final textual response into the session state under the specified key, aiding in conversational context and state management.
*   **`generate_content_config`**: Allows fine-tuning of the underlying LLM's generation parameters, such as `temperature` (randomness) or `max_output_tokens`.

### 2. Workflow Agents
These are specialized agents that control the execution flow of their sub-agents in **predefined, deterministic patterns**, without relying on an LLM for flow control. They are perfect for structured processes requiring predictable execution. The main types are:
*   **`SequentialAgent`**: Executes sub-agents one after another, in a strict, dependable sequence. This is used for pipelines where output from one agent must feed directly as input (via session state) to the next.
*   **`ParallelAgent`**: Executes multiple sub-agents concurrently, significantly reducing latency for independent tasks like parallel web research.
*   **`LoopAgent`**: Repeatedly runs a sequence of sub-agents until a maximum number of iterations (`max_iterations`) is reached, or until a termination condition is met, typically signalled by a sub-agent setting the `escalate=True` flag in its `Event Actions`. This is essential for iterative refinement patterns.

### 3. Custom Agents
Custom Agents offer the ultimate flexibility by allowing developers to define **arbitrary orchestration logic**. They are created by inheriting directly from `BaseAgent` and implementing the core execution logic within the asynchronous method, `_run_async_impl` (in Python). This approach is recommended after understanding the predefined agent types and allows for use cases like:
*   Implementing **unique workflow patterns** that don't fit sequential, parallel, or loop structures.
*   Incorporating calls to external APIs or databases directly within the orchestration flow control.
*   **Dynamic Agent Selection**, choosing which sub-agent(s) to run next based on the evaluation of the current situation or input.

An example is the Python `StoryFlowAgent`, which orchestrates generation, critique (via a nested `LoopAgent`), and conditional regeneration based on a tone check result saved in the session state.

## II. Multi-Agent Systems and Delegation

The true power of ADK lies in composing these different agent types into **hierarchical Multi-Agent Systems (MAS)**. Agents collaborate or coordinate to achieve a larger goal.

### Agent Hierarchy and Communication
Agents are connected through `parent_agent`/`sub_agents` relationships. Key interaction mechanisms include:

1.  **LLM-Driven Delegation (Auto Flow)**: A central agent (Coordinator) delegates requests to specialised `sub_agents` listed in its configuration based on their descriptive `description` and the Coordinator’s `instruction`. This dynamic routing requires the LLM to interpret the user's intent.
2.  **Explicit Invocation (`AgentTool`)**: An agent can call another specialised agent as a tool by wrapping it using the `AgentTool` class. The called agent's result is passed back to the calling agent (the parent) for summarisation or integration into the final response, allowing the parent agent to maintain control.
3.  **Transfer (Sub-Agent)**: When Agent A lists Agent B as a `sub_agent`, control of the conversation can be **transferred completely** to Agent B using the `transfer_to_agent` signal in an `EventActions` object. Once transferred, the new agent handles all subsequent user input.

Common patterns implemented via these primitives include the Coordinator/Dispatcher pattern, the Fan-Out/Gather pattern (using `ParallelAgent`), Hierarchical Planning, and the Generator/Critic pattern (using `SequentialAgent`).

## III. Context, State, and Memory Management

ADK provides structured ways to manage conversational context, which is crucial for meaningful, multi-turn interactions.

### 1. Session and State
A **`Session`** represents a single, ongoing interaction thread between a user and the agent system. It contains the chronological sequence of messages and actions (`Events`) for that interaction.

**`State`** (`session.state`) is the working memory or scratchpad for the session, storing temporary data relevant only to that specific conversation. Agents and tools can read from and write to the state to pass data between steps in a workflow. The `SessionService` (e.g., `InMemorySessionService` for testing or `VertexAiSessionService`/`DatabaseSessionService` for persistence) manages the lifecycle of `Session` objects.

### 2. Artifacts
**Artifacts** provide a mechanism for managing named, versioned binary data associated with a session or persistently with a user. They are designed to handle non-textual or large data blobs, such as images, audio clips, PDFs, or generated reports.

The `ArtifactService` handles versioning automatically when data is saved. ADK provides the `InMemoryArtifactService` for rapid prototyping and the **`GcsArtifactService`** for production environments requiring persistent storage via Google Cloud Storage.

### 3. Long-Term Memory
Distinct from session state, the **`MemoryService`** handles long-term knowledge, allowing agents to recall information about a user across * multiple* sessions or access external knowledge bases.

In Python ADK, implementations include the basic `InMemoryMemoryService` for demonstration and the powerful **`VertexAiRagMemoryService`**, which utilizes Vertex AI Retrieval Augmented Generation (RAG) for scalable, persistent, and semantically relevant knowledge retrieval. Agents use a tool (like `load_memory`) that queries the `MemoryService` via `ToolContext.search_memory()`.

## IV. Tools and External Capabilities

ADK features a **Rich Tool Ecosystem** that allows agents to perform actions beyond the LLM's intrinsic knowledge.

### 1. Custom and Function Tools
Any standard Python function or method can be automatically wrapped as a **`FunctionTool`** simply by including it in the agent's `tools` list. Key principles for defining effective tools include:
*   Using clear, descriptive function names and parameter names, as the LLM relies heavily on these for understanding.
*   Providing clear Python type hints (essential for schema generation) and detailed docstrings, which serve as the primary source of information for the LLM.
*   Returning a dictionary result, preferably including a `"status"` key (`'success'`, `'error'`, `'pending'`) for clarity to the LLM.

For tasks requiring significant time without blocking execution, the **`LongRunningFunctionTool`** (a subclass of `FunctionTool`) is used. The function returns an initial status (e.g., `pending` status and a `ticket-id`), pausing the agent run until the client sends back an intermediate or final status update.

### 2. Built-in and Ecosystem Tools
ADK integrates several powerful, built-in capabilities:
*   **Google Search**: Provided via the `google_search` tool for grounding responses with real-time information.
*   **Code Execution**: Enabled via `code_executor` and tools like **`BuiltInCodeExecutor`** or **`VertexAiCodeExecutor`**, which uses the Vertex Code Interpreter Extension for safe, sandboxed execution.
*   **Third-Party Integration**: ADK allows seamless integration of tools from other popular frameworks like **LangChain** and **CrewAI** by wrapping them using classes like `LangchainTool`.
*   **OpenAPI/REST**: The `OpenAPIToolset` automatically generates functional tools (`RestApiTool`) directly from an OpenAPI specification (YAML/JSON), simplifying API integration.

## V. Extensibility and Control with Callbacks

**Callbacks** are custom code snippets that serve as powerful hooks, running at specific points in the agent's execution process to inspect, modify, log, or enforce policy.

### Types of Callbacks
`LlmAgent`s support several specific callback types:

| Callback Type | When Called | Primary Use Case |
| :--- | :--- | :--- |
| **`before_model_callback`** | Just before the request is sent to the LLM. | Implementing **input guardrails** (e.g., blocking keywords) or **caching**. If it returns an `LlmResponse`, the actual LLM call is **skipped**. |
| **`after_model_callback`** | Immediately after the LLM response is received. | Sanitizing, reformatting, censoring, or parsing structured data from the LLM output. |
| **`before_tool_callback`** | Just before a tool (or function) is executed. | **Policy enforcement** (e.g., blocking tool use based on parameters) or cache validation. If it returns a dictionary, the tool execution is **skipped**, and the dictionary is used as the result. |
| **`after_tool_callback`** | Immediately after a tool finishes execution. | Post-processing, standardization, or logging tool outputs before they are sent back to the LLM. |

These callbacks provide a robust mechanism to implement comprehensive safety and security features, often leveraging a fast, cheap LLM (like Gemini Flash Lite) within a callback function to act as a **safety guardrail** against unsafe user inputs or tool inputs.

## VI. Streaming and Real-Time Interaction

ADK offers native support for streaming, culminating in **Bidirectional Streaming (Bidi-streaming or "live" mode)**, which brings low-latency voice and video interaction capability from the Gemini Live API to agents.

### Bidi-streaming Concepts
Bidi-streaming enables **real-time, two-way communication** that supports interruption, making conversations fluid and human-like. This is distinct from token-level streaming (which lacks interruption capability) or server-side streaming (which is one-way).

The streaming architecture involves:
*   The **`Runner.run_live()`** method, which starts a streaming session.
*   The **`LiveRequestQueue`**, which buffers and sequences incoming user messages (text, audio blobs, control signals) for orderly processing by the agent.
*   Events streamed back to the client via a transport layer like **WebSockets** or **Server-Sent Events (SSE)**.

### Runtime Configuration (`RunConfig`)
Streaming behaviour and modalities are configured using the `RunConfig` class. Key parameters include:
*   **`streaming_mode`**: Sets the behavior to `NONE`, `SSE` (one-way server-to-client streaming), or `BIDI` (bidirectional streaming).
*   **`response_modalities`**: Defines desired outputs (e.g., `["TEXT", "AUDIO"]`).
*   **`speech_config`**: Configures speech synthesis details (voice, language code) for audio responses.
*   **`save_input_blobs_as_artifacts`**: If `true`, input blobs (like uploaded files/video) are saved as run artifacts for debugging.
*   **`max_llm_calls`**: Limits the total number of LLM calls per run (default 500), preventing runaway processes and excessive costs.

## VII. Developer Lifecycle and Deployment

ADK provides tooling across the entire agent development lifecycle.

### Development and Evaluation
ADK supports a fast iteration loop through several tools:
*   **Development UI**: A built-in web interface (`adk web`) helps developers test, evaluate, debug, and showcase their agents locally.
*   **Event Inspection**: The Dev UI allows developers to inspect individual function calls, responses, model responses, and trace latency logs for each event.
*   **Evaluation**: The `adk eval` command line utility supports **systematic evaluation** against predefined datasets. Evaluation datasets, known as **Evalsets**, contain multiple conversational sessions (`eval_cases`) including user queries, expected tool use, intermediate responses, and a final reference response.

### Deployment
Agents can be containerised and deployed virtually anywhere. Core deployment targets supported by the documentation include:
*   **Vertex AI Agent Engine**: The easiest way to deploy ADK agents to a managed service in Vertex AI for enterprise-grade scalability and reliability.
*   **Cloud Run / GKE**: For full control, agents can be deployed to serverless Cloud Run or Kubernetes Engine (GKE), often integrated via a FastAPI application using ADK utilities.

### Contribution and Community
ADK welcomes community contributions for bug reports, feature requests, documentation improvements, and code contributions. Contributors must sign a **Contributor License Agreement (CLA)**.

***

In summary, the Agent Development Kit is like a high-end, modular sound mixing desk for AI applications: The **Agents** are the musicians (specialised functions), the **Workflow Agents** are the pre-programmed drum loops and sequences (deterministic flow), **LLM Agents** are the creative director deciding who plays when (dynamic delegation), **State and Memory** are the internal storage units and track archives (context persistence), and **Callbacks** are the built-in equalisers and safety limiters, ensuring every output meets defined standards before it leaves the desk. This architecture allows developers to orchestrate a complex, yet reliable, performance.

# Agent Development Kit (ADK)

Agent Development Kit (ADK)

## ADK Python Repository

Agent Development Kit (ADK)

An open-source, code-first Python toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.

Agent Development Kit (ADK) is a flexible and modular framework for developing and deploying AI agents. While optimized for Gemini and the Google ecosystem, ADK is model-agnostic, deployment-agnostic, and is built for compatibility with other frameworks. ADK was designed to make agent development feel more like software development, to make it easier for developers to create, deploy, and orchestrate agentic architectures that range from simple tasks to complex workflows.


✨ Key Features

Rich Tool Ecosystem
: Utilize pre-built tools, custom functions,
  OpenAPI specs, or integrate existing tools to give agents diverse
  capabilities, all for tight integration with the Google ecosystem.

Code-First Development
: Define agent logic, tools, and orchestration
  directly in Python for ultimate flexibility, testability, and versioning.

Modular Multi-Agent Systems
: Design scalable applications by composing
  multiple specialized agents into flexible hierarchies.

Deploy Anywhere
: Easily containerize and deploy agents on Cloud Run or
  scale seamlessly with Vertex AI Agent Engine.

🤖 Agent2Agent (A2A) Protocol and ADK Integration

For remote agent-to-agent communication, ADK integrates with the A2A protocol. See this  example for how they can work together.


🚀 Installation


Stable Release (Recommended)


You can install the latest stable version of ADK using pip:


pip install google-adk



The release cadence is weekly.


This version is recommended for most users as it represents the most recent official release.


Development Version


Bug fixes and new features are merged into the main branch on GitHub first. If you need access to changes that haven't been included in an official PyPI release yet, you can install directly from the main branch:


pip install git+https://github.com/google/adk-python.git@main



Note: The development version is built directly from the latest code commits. While it includes the newest fixes and features, it may also contain experimental changes or bugs not present in the stable release. Use it primarily for testing upcoming changes or accessing critical fixes before they are officially released.


📚 Documentation


Explore the full documentation for detailed guides on building, evaluating, and
deploying agents:




Documentation




🏁 Feature Highlight


Define a single agent:


from google.adk.agents import Agent
from google.adk.tools import google_search

root_agent = Agent(
    name="search_assistant",
    model="gemini-2.5-flash", # Or your preferred Gemini model
    instruction="You are a helpful assistant. Answer user questions using Google Search when needed.",
    description="An assistant that can search the web.",
    tools=[google_search]
)



Define a multi-agent system:


Define a multi-agent system with coordinator agent, greeter agent, and task execution agent. Then ADK engine and the model will guide the agents works together to accomplish the task.


from google.adk.agents import LlmAgent, BaseAgent

# Define individual agents
greeter = LlmAgent(name="greeter", model="gemini-2.5-flash", ...)
task_executor = LlmAgent(name="task_executor", model="gemini-2.5-flash", ...)

# Create parent agent and assign children via sub_agents
coordinator = LlmAgent(
    name="Coordinator",
    model="gemini-2.5-flash",
    description="I coordinate greetings and tasks.",
    sub_agents=[ # Assign sub_agents here
        greeter,
        task_executor
    ]
)



Development UI


A built-in development UI to help you test, evaluate, debug, and showcase your agent(s).




Evaluate Agents


adk eval \
    samples_for_testing/hello_world \
    samples_for_testing/hello_world/hello_world_eval_set_001.evalset.json



🤝 Contributing


We welcome contributions from the community! Whether it's bug reports, feature requests, documentation improvements, or code contributions, please see our
- 
General contribution guideline and flow
.
- Then if you want to contribute code, please read 
Code Contributing Guidelines
 to get started.


📄 License


This project is licensed under the Apache 2.0 License - see the LICENSE file for details.




Happy Agent Building!

**Source:** [adk-python repository](https://github.com/google/adk-python)

## Documentation
- [Custom agents](https://github.com/google/adk-docs/blob/main/docs/agents/custom-agents.md)
- [Agents](https://github.com/google/adk-docs/blob/main/docs/agents/index.md)
- [LLM Agent](https://github.com/google/adk-docs/blob/main/docs/agents/llm-agents.md)
- [Using Different Models with ADK](https://github.com/google/adk-docs/blob/main/docs/agents/models.md)
- [Multi-Agent Systems in ADK](https://github.com/google/adk-docs/blob/main/docs/agents/multi-agents.md)
- [Workflow Agents](https://github.com/google/adk-docs/blob/main/docs/agents/workflow-agents/index.md)
- [Loop agents](https://github.com/google/adk-docs/blob/main/docs/agents/workflow-agents/loop-agents.md)
- [Parallel agents](https://github.com/google/adk-docs/blob/main/docs/agents/workflow-agents/parallel-agents.md)
- [Sequential agents](https://github.com/google/adk-docs/blob/main/docs/agents/workflow-agents/sequential-agents.md)
- [API Reference](https://github.com/google/adk-docs/blob/main/docs/api-reference/index.md)
- [Artifacts](https://github.com/google/adk-docs/blob/main/docs/artifacts/index.md)
- [Design Patterns and Best Practices for Callbacks](https://github.com/google/adk-docs/blob/main/docs/callbacks/design-patterns-and-best-practices.md)
- [Callbacks: Observe, Customize, and Control Agent Behavior](https://github.com/google/adk-docs/blob/main/docs/callbacks/index.md)
- [Types of Callbacks](https://github.com/google/adk-docs/blob/main/docs/callbacks/types-of-callbacks.md)
- [Community Resources](https://github.com/google/adk-docs/blob/main/docs/community.md)
- [Context](https://github.com/google/adk-docs/blob/main/docs/context/index.md)
- [1. [`google/adk-python`](https://github.com/google/adk-python)](https://github.com/google/adk-docs/blob/main/docs/contributing-guide.md)
- [Deploy to Vertex AI Agent Engine](https://github.com/google/adk-docs/blob/main/docs/deploy/agent-engine.md)
- [Deploy to Cloud Run](https://github.com/google/adk-docs/blob/main/docs/deploy/cloud-run.md)
- [Deploy to GKE](https://github.com/google/adk-docs/blob/main/docs/deploy/gke.md)
- [Deploying Your Agent](https://github.com/google/adk-docs/blob/main/docs/deploy/index.md)
- [Why Evaluate Agents](https://github.com/google/adk-docs/blob/main/docs/evaluate/index.md)
- [Events](https://github.com/google/adk-docs/blob/main/docs/events/index.md)
- [Agent Development Kit (ADK)](https://github.com/google/adk-docs/blob/main/docs/get-started/about.md)
- [Get Started](https://github.com/google/adk-docs/blob/main/docs/get-started/index.md)
- [Installing ADK](https://github.com/google/adk-docs/blob/main/docs/get-started/installation.md)
- [Quickstart](https://github.com/google/adk-docs/blob/main/docs/get-started/quickstart.md)
- [Streaming Quickstarts](https://github.com/google/adk-docs/blob/main/docs/get-started/streaming/index.md)
- [Quickstart (Streaming / Java) {#adk-streaming-quickstart-java}](https://github.com/google/adk-docs/blob/main/docs/get-started/streaming/quickstart-streaming-java.md)
- [Quickstart (Streaming / Python) {#adk-streaming-quickstart}](https://github.com/google/adk-docs/blob/main/docs/get-started/streaming/quickstart-streaming.md)
- [Testing your Agents](https://github.com/google/adk-docs/blob/main/docs/get-started/testing.md)
- [What is Agent Development Kit?](https://github.com/google/adk-docs/blob/main/docs/index.md)
- [Model Context Protocol (MCP)](https://github.com/google/adk-docs/blob/main/docs/mcp/index.md)
- [Agent Observability with Arize AX](https://github.com/google/adk-docs/blob/main/docs/observability/arize-ax.md)
- [Agent Observability with Phoenix](https://github.com/google/adk-docs/blob/main/docs/observability/phoenix.md)
- [Runtime](https://github.com/google/adk-docs/blob/main/docs/runtime/index.md)
- [Runtime Configuration](https://github.com/google/adk-docs/blob/main/docs/runtime/runconfig.md)
- [Safety & Security for AI Agents](https://github.com/google/adk-docs/blob/main/docs/safety/index.md)
- [Introduction to Conversational Context: Session, State, and Memory](https://github.com/google/adk-docs/blob/main/docs/sessions/index.md)
- [Memory: Long-Term Knowledge with `MemoryService`](https://github.com/google/adk-docs/blob/main/docs/sessions/memory.md)
- [Session: Tracking Individual Conversations](https://github.com/google/adk-docs/blob/main/docs/sessions/session.md)
- [State: The Session's Scratchpad](https://github.com/google/adk-docs/blob/main/docs/sessions/state.md)
- [Configurating streaming behaviour](https://github.com/google/adk-docs/blob/main/docs/streaming/configuration.md)
- [Custom Audio Streaming app (WebSocket) {#custom-streaming-websocket}](https://github.com/google/adk-docs/blob/main/docs/streaming/custom-streaming-ws.md)
- [Custom Audio Streaming app (SSE) {#custom-streaming}](https://github.com/google/adk-docs/blob/main/docs/streaming/custom-streaming.md)
- [ADK Bidi-streaming development guide: Part 1 - Introduction](https://github.com/google/adk-docs/blob/main/docs/streaming/dev-guide/part1.md)
- [Bidi-streaming(live) in ADK](https://github.com/google/adk-docs/blob/main/docs/streaming/index.md)
- [Streaming Tools](https://github.com/google/adk-docs/blob/main/docs/streaming/streaming-tools.md)
- [Authenticating with Tools](https://github.com/google/adk-docs/blob/main/docs/tools/authentication.md)
- [Built-in tools](https://github.com/google/adk-docs/blob/main/docs/tools/built-in-tools.md)
- [Function tools](https://github.com/google/adk-docs/blob/main/docs/tools/function-tools.md)
- [Google Cloud Tools](https://github.com/google/adk-docs/blob/main/docs/tools/google-cloud-tools.md)
- [Tools](https://github.com/google/adk-docs/blob/main/docs/tools/index.md)
- [Model Context Protocol Tools](https://github.com/google/adk-docs/blob/main/docs/tools/mcp-tools.md)
- [OpenAPI Integration](https://github.com/google/adk-docs/blob/main/docs/tools/openapi-tools.md)
- [Third Party Tools](https://github.com/google/adk-docs/blob/main/docs/tools/third-party-tools.md)
- [Build Your First Intelligent Agent Team: A Progressive Weather Bot with ADK](https://github.com/google/adk-docs/blob/main/docs/tutorials/agent-team.md)
- [ADK Tutorials!](https://github.com/google/adk-docs/blob/main/docs/tutorials/index.md)
- [Python API Reference](https://github.com/google/adk-docs/blob/main/docs/api-reference/python/)